# 🎙️ Speech Emotion Recognition using LSTM-RNN

## 📌 Project Overview
This project focuses on recognizing human emotions from speech using the **RAVDESS dataset**.  
The model leverages **Long Short-Term Memory (LSTM-RNN)** architecture to capture temporal audio features, enabling accurate classification of emotions such as happiness, anger, sadness, and fear.  
It aims to enhance **human–computer interaction** by enabling machines to understand the emotional context of human speech.

---

## 🚀 Features
- Emotion detection from audio signals  
- LSTM-RNN–based deep learning model  
- Streamlit web interface for easy testing and deployment  
- Visualization of training accuracy and loss  
- Supports multiple emotions from the RAVDESS dataset  

---

## 🧠 Model Performance
- **Dataset:** RAVDESS (Ryerson Audio-Visual Database of Emotional Speech and Song)  
- **Model Accuracy:** ~65% on test data  
- **Emotions Classified:** Happy, Angry, Sad, Fear, Neutral, and others  

---

## 🧩 Tech Stack
- **Programming Language:** Python  
- **Libraries & Frameworks:** TensorFlow/Keras, Librosa, NumPy, Pandas, Matplotlib  
- **Frontend:** Streamlit  
- **Development Environment:** VS Code / Google Colab  

---

## ⚙️ How to Run
1. Clone this repository  
   ```bash
   git clone https://github.com/your-username/speech-emotion-recognition.git
